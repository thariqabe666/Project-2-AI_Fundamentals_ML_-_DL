# ðŸ“¡ Telecom Customer Churn Prediction Project  
**Capstone Project â€“ Module 2: AI Engineering**  
*Purwadhika Digital Technology School*

## 1. Project Introduction  
Build a complete **end-to-end machine-learning pipeline** that predicts which customers of a fictional telecom company are about to **churn** (cancel their subscription).  
Every stage of the data-science lifecycle is covered: business problem â†’ clean data â†’ explore â†’ engineer features â†’ train 6 models â†’ pick the winner â†’ prove the dollars saved.

## 2. Business Problem & Objective  
- **Problem**: In telecom, losing a customer costs 5â€“10Ã— more than keeping one.  
- **Objective**: Flag high-risk churners **early** so the retention team can send the right offer and keep revenue flowing.

## 3. Project Methodology  
1. **Data Cleaning** â€“ zero duplicates, consistent types  
2. **EDA** â€“ beautiful charts that reveal who churns and why  
3. **Feature Engineering** â€“ smart new columns:  
   - `ProfilRisiko` (risk profile)  
   - `EstimatedTotalCharges` (lifetime value proxy)  
   - `JumlahLayanan` (service bundle count)  
   - Ordinal + One-Hot encoding for every category  
4. **Modeling** â€“ head-to-head battle of 6 classifiers:  
   Logistic Regression | Random Forest | XGBoost | SVM | KNN | **Naive Bayes**  
5. **Evaluation** â€“ **Recall is king** (catch as many real churners as possible)  
6. **Business Simulation** â€“ â€œWhat if we run this model every month?â€

## 4. Key Results & Insights  
- **Winner: Naive Bayes** â†’ **80 % Recall** on test set  
  (catches 8 out of every 10 future churners)  
- Most powerful predictors = the features **we invented**, especially money-related ones.  
- Monthly **net savings: ~$4,272**  
  (60 % retention success Ã— $25 average save â€“ 15 % campaign cost)

## 5. Tech Stack  
- Python 3  
- Jupyter Notebook  
- Pandas & NumPy â†’ data wrangling  
- Matplotlib & Seaborn â†’ story-telling visuals  
- Scikit-learn â†’ preprocessing, models, metrics  
- XGBoost â†’ gradient boosting  
- Pickle â†’ `final_model.pkl` ready for production  

## 6. File Structure  
```
.  
â”œâ”€â”€ capstone_2_thariq_ahmad.ipynb          # Full notebook (run top-to-bottom)  
â”œâ”€â”€ final_model.pkl                        # Trained Naive Bayes, load & predict!  
â”œâ”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv   # Raw dataset  
â””â”€â”€ README.md                              # Youâ€™re reading the English version  
```

## 7. Reproduce in 5 Minutes  
```bash
# 1. Clone
git clone https://github.com/your-username/your-repo.git
cd your-repo

# 2. Virtual env
python -m venv venv
# Windows
.\venv\Scripts\activate
# macOS / Linux
source venv/bin/activate

# 3. Install
cat > requirements.txt <<EOF
pandas
numpy
matplotlib
seaborn
scikit-learn
xgboost
jupyter
EOF
pip install -r requirements.txt

# 4. Fire up Jupyter
jupyter notebook
```
Open `capstone_2_thariq_ahmad.ipynb` â†’ **Run All**.  
Watch the model train, charts pop, and dollar savings appear.

## Ready when you are  
Load the model in one line:  
```python
import pickle
model = pickle.load(open('final_model.pkl', 'rb'))
prediction = model.predict(new_customer_data)
```
Start saving customers (and money) today! ðŸš€
